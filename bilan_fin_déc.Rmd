---
title: "bilan fin décembre"
author: "Team PAT"
date: "`r Sys.Date()`"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r}
# packages à charger
library(purrr)
library(easyCODA)    # Greenacre 
library(FactoMineR)

library(tidyverse)
library(dplyr)

library(Factoshiny)
library(ggplot2)
library(ggrepel)
library(RColorBrewer)
library(plotly)
library(tidyr)

```

```{r}
# chargement des données des autres RMD

load(file = "data/clust.RData")     # coordonnéees des mots = formes fortes 
load(file = "data/documents.RData") # comptage des lemmes dans les doc
load(file = "data/vocab.RData")     # identification des mots 
load(file = "data/mfa.df.final.RData")


```



A partir des formes fortes obtenues par MFA, on souhaite extraire les compositions des descriptions des PAT, grâce à la fréquence d'apparition de chaque terme de chaque topic dans les descriptions des PAT tokenisées.

Création du df 
```{r}
df_textes <- imap_dfr(documents, function(mat, nom_doc) {
  
  # index des mots
  idx <- mat[1, ]
  
  # fréquences
  freq <- mat[2, ]
  
  # conversion index -> mots
  mots <- vocab[idx]
  
  # répéter les mots selon la fréquence
  texte <- paste(
    rep(mots, times = freq),
    collapse = " "
  )
  
  tibble(
    doc = nom_doc,
    texte = texte
  )
})

df_textes

```



On crée le data frame vide: 361 colonnes et 132 lignes 
```{r}
df_mots <- tibble(mot = rownames(mfa.df.final)) # une colonne pour les mots 

df_cross <- crossing(df_mots, df_textes) # tous les croisement des mots (132) avec tous les textes (360)

df_count <- df_cross %>%  mutate(occurrence = str_count(texte, fixed(mot)))  # comptage des occurences de chaque mot dans le texte 

df_resultat <- df_count %>%
  select(mot, doc, occurrence) %>%
  pivot_wider(
    names_from = doc,
    values_from = occurrence
  )

rm(df_mots)
rm(df_cross)
rm(df_count)

# on trie les mots (lignes) du doc clust par ordre alphabétique pour ensuite récupérer les clusters des mots 
clust <- clust %>% arrange(by = word)
  
df_resultat$cluster <- clust$clust

df_resultat.final <- data.frame(df_resultat %>%
  group_by(cluster) %>%
  summarise(across(where(is.numeric), sum, na.rm = TRUE)))


# sum(is.na(df))
# 
# max.col(df)
# 
# colnames(df)[max.col(df)]
# 
# 
# 
# summary(colSums(df_resultat.final[,-1]))

df_resultat.final <- df_resultat.final[,-1]

```


Filtre pour supp les docs qui ont pas assez de mots qui se retrouvent 

On veut filtrer les PAT qui n'ont pas assez de mots issus de nos formes fortes, ou placer la limite ? 
On trace l'histogramme du nombre total de termes issus de l'ensemble de nos topics (formes fortes). On avait fixé la limite à 10 termes minimum issus des formes fortes pour que le PAT soit conservé pour la classification 

```{r}
hist(colSums(df_resultat.final), breaks = 200, xlim = range(0:150))
abline(v = 10, col = "blue4", lwd = 3)
```

On va créer le data frame filtré contenant uniquement les PAT avec plus de 10 termes issus des formes fortes. 
```{r}
df_filtre <- as.data.frame(df_resultat.final[, colSums(df_resultat.final) > 10])
```

On va créer le tableau contenant les fréquences de chaque topic à partir de nos comptages.
```{r}
df <- data.frame(apply(df_filtre,2,function(x) x/sum(x)*100))
df[df=="NaN"] <- 0
```

On s'intéresse ensuite aux PAT qui sont les plus purs, c'est à dire qui prennent la valeur maximale pour un des topics. On va essayer de comprendre la solidité de notre mesure de fréquence en comparant ces PAT avec leur description. 

On pourrait utiliser ces PAT comme exemple pour fournir à un modèle de langage de l'information supplémentaire liée à chaque topic pour en extraire le nom de la variable latente ensuite. 

```{r}
df[,max.col(df)] # on cherche les textes les plus purs de chaque topic et on affiche leur profils de répartition des topics 
```

Analyse de ces PAT "purs" 
=> qualitative : à la main, en comparant avec la base
```{r}

```

=> qualitative : avec modèle de langage 
```{r}

```


On va transposer le df pour obtenir un tableau de données avec 6 colonnes (les titres sont issus des noms extraits par extraction des variables latentes avec NailR) et autant de lignes que de PAT après sélection (PAT ayant une description + au moins un certain nb de caractères dans la description et au moins 10 termes issus de nos formes fortes)
```{r}
df.t <- data.frame(t(df))
colnames(df.t) <- c("Gouvernance", "Alimentation Collective, Durable et Solidaire", "Démographie" , "Environnement", "Economie alimentaire", "Secteur agricole")
rownames(df.t) <- as.numeric(gsub("text", "", rownames(df.t)))

df.t <- df.t[order(as.numeric(rownames(df.t))), ]
```

Comment se répartissent les vecteurs de composition des PAT en 6 topics ? 

```{r}
summary(df.t)
```


```{r}
df.t %>%
  pivot_longer(cols = everything(),
               names_to = "Groupe",
               values_to = "Valeur") %>%
  ggplot(aes(x = Groupe, y = Valeur)) +
  geom_boxplot(fill = "skyblue") +
  theme_minimal() +
  labs(title = "Distribution par groupe",
       x = "Groupe",
       y = "Valeur")

# from gemini request 
# 12.12.25 Rmd
```

On veut classifier nos PAT selon ces vecteurs de proportion de nos 6 topics. 

⚠️ Ces vecteurs de proportions sont construits sur l'occurence des mots représentatifs de chaque topic dans chacun des PAT. Ces mots sont les termes ayant les indices frex les plus forts, consolidés par de nombreuses éxecutions de la LDA, puis filtrés pour supprimer les mots n'apparaissant que dans un seul topic d'une seule LDA, puis regroupés dans des formes fortes par classification hiérarchique précédée d'une MFA. 

```{r}
# zeros ?

100*sum(df.t==0)/(nrow(df.t)*(ncol(df.t))) # 6 % de zéros
```


On va coder nous mêmes le remplacement des zéros par BDL = remplacement de chaque zéro par 2/3 de la valeur minimale de chaque colonne 
```{r}
# df.t[df.t==0] <- 1000
# df.t[minRow(df.t),]

min <- apply(df.t, 2, function(x) min(x[x != 0]))
min <- (2/3)*min

# replace les zero par la valeur 
for (i in seq_along(min)) {
  df.t[df.t[, i] == 0, i] <- min[i]
}

summary(rowSums(df.t)) # du coup, toutes les fréquences ne sommes plus à 100

# on recalcule nos fréquences 
df.t <- t(apply(df.t,1,function(x) (x/sum(x))*100))


######### nb : easyCODA::LRA => compute une CLR 

res.alr <- CLR(df.t, weight = F)
# res.pca <- easyCODA::PCA(res.alr, nd = 5)
# easyCODA::PLOT.PCA(res.pca)

res.ward <- easyCODA::WARD(res.alr, weight = F)

```


```{r, ignore = T}
######################################
# PCA sur le res de CLR 
res.pca <- FactoMineR::PCA(res.alr$LR, ncp = 3)
barplot(res.pca$eig[,2])

res.hcpc <- HCPC(res.pca, nb.clust = 3)

res.hcpc$desc.var
# Variables => donc topic sous ou sur représentés dans le cluster

# clust1 :   Gouvernance, démographie, env   
# clust2 :   Gouvernance, secteur agricole, justice sociale 
# clust3 :   Eco alim, secteur agricole, env 

res.hcpc$desc.ind 
# clust1 : 441        36       457       318       211 
# clust2 : 443       122       341       323       269 
# clust3 : 178       174       167       181       319 
```

PCA sur le tableau de données brut
```{r}
res.pca.brut <- FactoMineR::PCA(df.t)
barplot(res.pca.brut$eig[,2])
res.hcpc.brut <- HCPC(res.pca.brut, nb.clust = -1)

# test avec Nb opt = 3 clust 
HCPC(res.pca.brut, nb.clust = 3)$desc.var
# clust 1 : eco alim + environnement => production alimentaire verte 
# clust 2 : secteur agri + alim durable et sociale (env - ) => soutien agricole et justice sociale 
# clust 3 : démo + alim durable + gouvernance (eco alim -) => soutien à la population 

HCPC(res.pca.brut, nb.clust = 3)$desc.ind

# test avec NB.CLUST = 6
HCPC(res.pca.brut, nb.clust = 6)$desc.var
# clust 1 : eco alim 
# clust 2 : secteur agri 
# clust 3 : environnement
# clust 4 : gouvernance
# clust 5 : alim durable et sociale 
# clust 6 : démo 

```

CA sur table de comptage
```{r}
df.ca <- data.frame(t(df_filtre))
colnames(df.ca) <- colnames(df.t)
rownames(df.ca) <- as.numeric(gsub("text", "", rownames(df.ca)))
df.ca <- df.ca[order(as.numeric(rownames(df.ca))), ]

res.ca <- FactoMineR::CA(df.ca)
plot.CA(res.ca, invisible = "row")

res.hcpc.ca <- HCPC(res.ca, nb.clust = -1)
res.hcpc.ca$`1` # eco alim, env
res.hcpc.ca$`2` # agri + alim coll durable 
res.hcpc.ca$`3` # gouvernance 
```


Et CA sur le tableau avec transformations log 
```{r}
res <- ALR(df.t, weight = F)
res.ca.clr <- FactoMineR::CA(res.clr$LR)
```


